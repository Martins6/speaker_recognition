{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Extracting features from Voices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import librosa\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "# Setting working directory\n",
    "os.chdir(Path('/home/adriel_martins/Documents/voice_recognition'))"
   ]
  },
  {
   "source": [
    "## Preparing the data\n",
    "\n",
    "Initial file dataframe is from the csv that we made with the 'LibriSpeech_Files_Pre_Processing' notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id              soundfile\n",
       "0  8468  8468-286673-0030.flac\n",
       "1  1235  1235-135883-0028.flac\n",
       "2  2911    2911-7601-0013.flac\n",
       "3  8797  8797-294123-0053.flac\n",
       "4  3214  3214-167606-0032.flac\n",
       "5   460   460-172359-0004.flac\n",
       "6   150   150-126107-0004.flac\n",
       "7  5750   5750-35690-0019.flac\n",
       "8  8465  8465-246942-0005.flac\n",
       "9  3259  3259-158083-0054.flac"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>soundfile</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8468</td>\n      <td>8468-286673-0030.flac</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1235</td>\n      <td>1235-135883-0028.flac</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2911</td>\n      <td>2911-7601-0013.flac</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8797</td>\n      <td>8797-294123-0053.flac</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3214</td>\n      <td>3214-167606-0032.flac</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>460</td>\n      <td>460-172359-0004.flac</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>150</td>\n      <td>150-126107-0004.flac</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5750</td>\n      <td>5750-35690-0019.flac</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8465</td>\n      <td>8465-246942-0005.flac</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3259</td>\n      <td>3259-158083-0054.flac</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv(Path('Data/id_and_soundfiles_LibriSpeech.csv'))\n",
    "df.head(10)"
   ]
  },
  {
   "source": [
    "## Feature Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main source for the choosing of the feature is Jurgen Arias (2020).\n",
    "\n",
    "def extract_features(row):\n",
    "    \n",
    "    # Sets the name to be the path to where the file is in my computer\n",
    "    path = Path('LibriSpeech/train-clean-100')\n",
    "    folder_paths_to_add = row.soundfile.split('-')\n",
    "    for index, dir in enumerate(folder_paths_to_add):\n",
    "        if index == 2:\n",
    "            break\n",
    "        path = path.joinpath(dir)\n",
    "    path = path / row.soundfile\n",
    "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "    # Sample rate is set to 22050 by default\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast') \n",
    "\n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # Computes a chromagram from a waveform or power spectrogram.\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes a mel-scaled spectrogram.\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes spectral contrast\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes the tonal centroid features (tonnetz)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    # We add also the speaker_id of each file as a label at the end\n",
    "    label = row.id\n",
    "\n",
    "    return mfccs, chroma, mel, contrast, tonnetz, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to start the timer to see how long it takes to extract the features\n",
    "startTime = datetime.now()\n",
    "\n",
    "# Applying the function to the train data by accessing each row of the dataframe\n",
    "features_label = df.apply(extract_features, axis=1)\n",
    "\n",
    "# Code to see how long it took\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Path('Data/features_label'), features_label)"
   ]
  }
 ]
}