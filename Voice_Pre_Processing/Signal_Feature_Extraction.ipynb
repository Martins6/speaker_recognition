{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Extracting features from Voices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import librosa\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "# Setting working directory\n",
    "os.chdir(Path('/home/adriel_martins/Documents/voice_recognition'))"
   ]
  },
  {
   "source": [
    "## Preparing the data\n",
    "\n",
    "Initial file dataframe is from the csv that we made with the 'LibriSpeech_Files_Pre_Processing' notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id              soundfile\n",
       "0   298   298-126791-0010.flac\n",
       "1   298   298-126791-0012.flac\n",
       "2   298   298-126791-0049.flac\n",
       "3   298   298-126791-0037.flac\n",
       "4   298   298-126791-0063.flac\n",
       "5  2514  2514-149482-0071.flac\n",
       "6  2514  2514-149482-0028.flac\n",
       "7  2514  2514-149482-0067.flac\n",
       "8  2514  2514-149482-0032.flac\n",
       "9  2514  2514-149482-0047.flac"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>soundfile</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>298</td>\n      <td>298-126791-0010.flac</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>298</td>\n      <td>298-126791-0012.flac</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>298</td>\n      <td>298-126791-0049.flac</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>298</td>\n      <td>298-126791-0037.flac</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>298</td>\n      <td>298-126791-0063.flac</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2514</td>\n      <td>2514-149482-0071.flac</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2514</td>\n      <td>2514-149482-0028.flac</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2514</td>\n      <td>2514-149482-0067.flac</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2514</td>\n      <td>2514-149482-0032.flac</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2514</td>\n      <td>2514-149482-0047.flac</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df = pd.read_csv(Path('Data/id_and_soundfiles_LibriSpeech.csv'))\n",
    "df.head(10)"
   ]
  },
  {
   "source": [
    "## Feature Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main source for the choosing of the feature is Jurgen Arias (2020).\n",
    "\n",
    "def extract_features(row):\n",
    "    \n",
    "    # Sets the name to be the path to where the file is in my computer\n",
    "    path = Path('LibriSpeech/train-clean-100')\n",
    "    folder_paths_to_add = row.soundfile.split('-')\n",
    "    for index, dir in enumerate(folder_paths_to_add):\n",
    "        if index == 2:\n",
    "            break\n",
    "        path = path.joinpath(dir)\n",
    "    path = path / row.soundfile\n",
    "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "    # Sample rate is set to 22050 by default\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast') \n",
    "\n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # Computes a chromagram from a waveform or power spectrogram.\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes a mel-scaled spectrogram.\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes spectral contrast\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes the tonal centroid features (tonnetz)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    # We add also the speaker_id of each file as a label at the end\n",
    "    label = row.id\n",
    "\n",
    "    return mfccs, chroma, mel, contrast, tonnetz, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:12:28.837143\n"
     ]
    }
   ],
   "source": [
    "# Code to start the timer to see how long it takes to extract the features\n",
    "startTime = datetime.now()\n",
    "\n",
    "# Applying the function to the train data by accessing each row of the dataframe\n",
    "features_label = df.apply(extract_features, axis=1)\n",
    "\n",
    "# Code to see how long it took\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      ([-289.34943, 110.6154, -67.3782, 59.304237, -...\n",
       "1      ([-320.5409, 105.738525, -56.98817, 52.488617,...\n",
       "2      ([-311.92624, 104.054054, -59.412125, 57.68102...\n",
       "3      ([-310.9264, 96.11666, -56.33535, 57.83569, -1...\n",
       "4      ([-294.8751, 113.68041, -62.691093, 48.88425, ...\n",
       "                             ...                        \n",
       "495    ([-392.83832, 103.10235, -21.629827, 35.794468...\n",
       "496    ([-366.55304, 114.450096, -13.166514, 37.16646...\n",
       "497    ([-378.58362, 119.243164, -22.32459, 43.95746,...\n",
       "498    ([-364.83, 118.77677, -26.965506, 41.79388, -7...\n",
       "499    ([-371.5594, 116.94956, -21.727648, 40.800175,...\n",
       "Length: 500, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "features_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Path('Data/features_label'), features_label)"
   ]
  }
 ]
}