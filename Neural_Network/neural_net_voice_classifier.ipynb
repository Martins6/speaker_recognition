{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Voice Recognition with Deep Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# For preprocessing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "## Plotting data\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "# set current working dir\n",
    "os.chdir('/home/adriel_martins/Documents/voice_recognition')"
   ]
  },
  {
   "source": [
    "## Preparing the data\n",
    "\n",
    "Inital data is from the Jurgen Arias's notebook preprocessing of data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-366.63562   ,   96.04874   ,  -69.84662   ,   76.36943   ,\n",
       "         -24.817017  ,   14.41616   ,    4.2905197 ,   -1.8795805 ,\n",
       "          13.70058   ,    3.6543803 ,    8.991205  ,   -3.1601498 ,\n",
       "           5.1049666 ,    2.6289887 ,    1.0638338 ,   -3.784181  ,\n",
       "           1.1059349 ,    1.8543453 ,    2.2196708 ,    3.0452476 ,\n",
       "           2.9182453 ,    4.099081  ,    0.39878955,    5.7587442 ,\n",
       "           0.7864756 ,    3.3036218 ,    1.7996112 ,   -0.8484667 ,\n",
       "           3.3366387 ,    2.934917  ,    2.9008343 ,    0.5252678 ,\n",
       "           2.3906317 ,    1.9600887 ,    2.8523176 ,    3.2463658 ,\n",
       "           3.8902597 ,    4.625333  ,    3.8027694 ,    5.2710724 ],\n",
       "       dtype=float32),\n",
       " array([0.55214745, 0.5712805 , 0.598977  , 0.60294086, 0.61977226,\n",
       "        0.6546082 , 0.64055675, 0.62010676, 0.586103  , 0.58701015,\n",
       "        0.6026565 , 0.5885016 ], dtype=float32),\n",
       " array([7.36393154e-01, 2.26960018e-01, 1.12153115e-02, 6.72356132e-03,\n",
       "        1.60283357e-01, 1.04996264e+00, 1.69271612e+00, 1.51260221e+00,\n",
       "        6.70031786e-01, 7.77193159e-02, 9.06617045e-02, 1.75315887e-01,\n",
       "        4.45169151e-01, 4.26027209e-01, 3.44188660e-01, 3.02109897e-01,\n",
       "        2.92879671e-01, 3.04482281e-01, 1.36124685e-01, 2.27442175e-01,\n",
       "        2.50024676e-01, 1.74414232e-01, 2.13230938e-01, 1.41726628e-01,\n",
       "        2.41585061e-01, 3.22785288e-01, 2.98365116e-01, 1.89172059e-01,\n",
       "        1.34754032e-01, 3.17638576e-01, 1.97704405e-01, 1.35105684e-01,\n",
       "        2.19430730e-01, 1.44752666e-01, 8.50184634e-02, 5.09311110e-02,\n",
       "        6.58019930e-02, 1.15728281e-01, 9.10342038e-02, 7.85010532e-02,\n",
       "        2.56981738e-02, 2.67956294e-02, 3.66868228e-02, 5.10502160e-02,\n",
       "        7.88843855e-02, 4.09643129e-02, 2.19151583e-02, 1.39991287e-02,\n",
       "        1.58330221e-02, 2.10909341e-02, 3.40278633e-02, 2.59628408e-02,\n",
       "        1.91887300e-02, 2.31814981e-02, 3.32052968e-02, 4.74756137e-02,\n",
       "        3.55099402e-02, 3.63404602e-02, 2.60921139e-02, 6.48061633e-02,\n",
       "        5.34315892e-02, 4.20552716e-02, 6.34406433e-02, 4.86457162e-02,\n",
       "        5.94084635e-02, 3.03471535e-02, 3.37635688e-02, 2.64143944e-02,\n",
       "        4.54775840e-02, 6.88221529e-02, 6.01135604e-02, 3.86072025e-02,\n",
       "        8.90069082e-02, 7.81564713e-02, 8.62824842e-02, 9.77552086e-02,\n",
       "        1.20321050e-01, 1.55992091e-01, 1.82784796e-01, 1.23282515e-01,\n",
       "        1.14377715e-01, 8.78297687e-02, 8.18230137e-02, 1.21182926e-01,\n",
       "        8.47864598e-02, 7.54506588e-02, 7.44194612e-02, 9.79388729e-02,\n",
       "        1.86049551e-01, 8.94172341e-02, 8.36229250e-02, 1.04077712e-01,\n",
       "        8.41716453e-02, 1.30368516e-01, 7.69464523e-02, 5.18603511e-02,\n",
       "        1.59405813e-01, 1.24601379e-01, 9.36513096e-02, 6.20439351e-02,\n",
       "        5.51076010e-02, 5.17743006e-02, 8.11051428e-02, 8.40541199e-02,\n",
       "        6.40072748e-02, 4.62091565e-02, 2.96751168e-02, 1.51876984e-02,\n",
       "        1.02534117e-02, 7.85927474e-03, 5.14092203e-03, 3.08627938e-03,\n",
       "        1.10633846e-03, 2.67842173e-04, 2.54571260e-05, 1.35632877e-06,\n",
       "        2.68283102e-08, 2.43970705e-10, 1.09221389e-10, 2.12689061e-10,\n",
       "        3.03250591e-10, 2.78295109e-10, 2.83268936e-10, 3.29108629e-10,\n",
       "        4.85837315e-10, 4.65975258e-10, 4.27477165e-10, 4.49419169e-10],\n",
       "       dtype=float32),\n",
       " array([21.80623092, 16.57882657, 17.61829735, 16.63343419, 17.96622373,\n",
       "        23.20961587, 41.62188849]),\n",
       " array([-0.00775333,  0.05804255, -0.05668859,  0.0528246 ,  0.01333635,\n",
       "         0.01987121]),\n",
       " '0')"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# This numpy array represents 5 features extracted from the signal\n",
    "# and the respective label\n",
    "features_label = np.load('Data/features_label.npy', allow_pickle=True)\n",
    "\n",
    "features_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_feats(in_feats):\n",
    "    x = in_feats.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled, columns=in_feats.columns)\n",
    "\n",
    "# Apply some data formatting\n",
    "def format_data(data):\n",
    "    # One-hot encode 'Embarked' column\n",
    "    data = pd.get_dummies(data, columns=['Sex','Embarked'])\n",
    "    # Drop columns that require additional processing\n",
    "    data = data.drop(['Name','Ticket','Cabin'], axis=1)\n",
    "    # Fill null values with the mean of the column\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "    if 'Survived' in data.columns:\n",
    "        data_y = data['Survived']\n",
    "        data_x = data.drop(['Survived'], axis=1)\n",
    "        data_x = format_feats(data_x)\n",
    "        print('found it')\n",
    "        return data_x, data_y\n",
    "    else:\n",
    "        return format_feats(data)\n",
    "\n",
    "# This should split the data into our features and our labels\n",
    "feats, labels = format_data(df)\n",
    "feats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting between validation and training\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(feats, labels, test_size = 0.1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train.to_numpy())\n",
    "Y_train = torch.LongTensor(Y_train.to_numpy())\n",
    "\n",
    "X_test = torch.FloatTensor(X_test.to_numpy())\n",
    "Y_test = torch.LongTensor(Y_test.to_numpy())\n",
    "\n",
    "X_validation = torch.FloatTensor(X_validation.to_numpy())\n",
    "Y_validation = torch.LongTensor(Y_validation.to_numpy())"
   ]
  },
  {
   "source": [
    "## Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_feat, output_feat):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_feat, 250) \n",
    "        self.fc2 = nn.Linear(250, output_feat)\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = Classifier(input_feat=X_train.size()[1], output_feat=2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(input_feat=X_train.size()[1], output_feat=2)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to +infinity\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    lower_bound_index = 0\n",
    "    for upper_bound_index in range(1,11):\n",
    "    \n",
    "        index_range = range(lower_bound_index,\n",
    "                            (upper_bound_index*(len(X_train)//10)))\n",
    "\n",
    "        lower_bound_index = upper_bound_index\n",
    "\n",
    "        x = X_train[index_range]\n",
    "        y = Y_train[index_range]\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(x) # log_ps\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*X_train.size(0)\n",
    "\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # prep model for evaluation\n",
    "    lower_bound_index = 0\n",
    "    for upper_bound_index in range(1,11):\n",
    "    \n",
    "        index_range = range(lower_bound_index,\n",
    "                            (upper_bound_index*(len(X_validation)//10)))\n",
    "\n",
    "        lower_bound_index = upper_bound_index\n",
    "\n",
    "        x = X_validation[index_range]\n",
    "        y = Y_validation[index_range]\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(x) # log_ps\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y) \n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*X_validation.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(X_train)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_loss = valid_loss/len(X_validation)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(X_train.size()[1], 2)\n",
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "test_losses = []\n",
    "\n",
    "model.eval() # prepare model for evaluation\n",
    "# To speed up calculations, forget the gradients, etc.\n",
    "with torch.no_grad():\n",
    "    lower_bound_index = 0\n",
    "    for upper_bound_index in range(1,11):\n",
    "    \n",
    "        index_range = range(lower_bound_index,\n",
    "                            (upper_bound_index*(len(X_validation)//10)))\n",
    "\n",
    "        lower_bound_index = upper_bound_index\n",
    "\n",
    "        x = X_test[index_range]\n",
    "        y = Y_test[index_range]\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(x) # log_ps\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*x.size(0)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        ps = torch.exp(output) # cuz our model outputs log-probability\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "\n",
    "        equals = (top_class == y.view(*top_class.shape))\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))/(len(range(1,11)))\n",
    "\n",
    "        print(\"Test Loss: {:.3f}.. \".format(test_loss/len(X_test)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}