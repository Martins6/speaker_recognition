{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Voice Recognition with Deep Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# For preprocessing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "## Plotting data\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "# set current working dir\n",
    "os.chdir(Path('/home/adriel_martins/Documents/voice_recognition'))"
   ]
  },
  {
   "source": [
    "## Reading Data\n",
    "\n",
    "Our initial data comes from the numpy array that we made with the 'Signal_Feature_Extraction' notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-3.6667053e+02,  1.1917808e+02, -1.1537009e+01,  3.7124893e+01,\n",
       "         4.5089059e+00,  1.2463992e+00, -1.6520576e+01, -1.9386774e+01,\n",
       "        -1.1613708e+01, -7.7634439e+00, -2.3502064e+00, -6.0884881e+00,\n",
       "         5.2901429e-01, -4.4644852e+00,  5.4440641e+00,  1.7343061e+00,\n",
       "        -5.1755018e+00, -2.5856745e+00, -6.8001833e+00, -1.0892000e+00,\n",
       "        -7.3762760e+00, -8.1930122e+00, -2.6990726e+00, -3.3281727e+00,\n",
       "        -3.3485827e+00, -1.0064723e+00,  2.1757193e-01, -3.9501967e+00,\n",
       "        -1.3473492e+00, -7.9314518e-01, -4.0448556e+00, -4.8921371e+00,\n",
       "        -2.9967959e+00, -1.5930473e+00, -1.2883358e+00, -9.3357992e-01,\n",
       "        -4.6056266e+00, -1.8098402e+00, -1.5934964e+00, -1.9052585e+00],\n",
       "       dtype=float32),\n",
       " array([0.72523016, 0.6711473 , 0.59517676, 0.52301925, 0.5067012 ,\n",
       "        0.5643972 , 0.60795456, 0.618594  , 0.62857383, 0.6287439 ,\n",
       "        0.6406759 , 0.6774414 ], dtype=float32),\n",
       " array([9.15813434e-04, 5.32634184e-03, 9.42190289e-02, 4.34629083e-01,\n",
       "        1.31306756e+00, 8.16799700e-01, 6.65282547e-01, 1.35947931e+00,\n",
       "        1.53065562e+00, 1.41454458e+00, 1.26398885e+00, 1.49706197e+00,\n",
       "        1.35629618e+00, 1.56520331e+00, 1.98016942e+00, 2.72717142e+00,\n",
       "        3.18160796e+00, 3.88548040e+00, 4.20716810e+00, 6.71873522e+00,\n",
       "        5.32497501e+00, 1.74719918e+00, 8.03776026e-01, 4.71090943e-01,\n",
       "        3.36932987e-01, 2.28603080e-01, 1.48946702e-01, 1.26946375e-01,\n",
       "        1.02228843e-01, 1.29811257e-01, 1.65645406e-01, 7.56597593e-02,\n",
       "        4.71888371e-02, 3.70787308e-02, 5.25808595e-02, 5.33325337e-02,\n",
       "        5.05994596e-02, 3.63911800e-02, 5.33782989e-02, 4.40209731e-02,\n",
       "        4.13521528e-02, 2.69511491e-02, 2.17734110e-02, 2.39836313e-02,\n",
       "        3.12204324e-02, 3.80327813e-02, 2.68923994e-02, 2.31946614e-02,\n",
       "        3.78192142e-02, 2.99451947e-02, 3.87391523e-02, 8.45815986e-02,\n",
       "        1.06681794e-01, 9.47913304e-02, 9.82950330e-02, 7.62407035e-02,\n",
       "        9.21591371e-02, 8.78935084e-02, 7.63656944e-02, 9.26686525e-02,\n",
       "        4.58290204e-02, 4.96059544e-02, 4.08079997e-02, 2.11884938e-02,\n",
       "        2.25308146e-02, 2.16737948e-02, 2.38036476e-02, 2.41059382e-02,\n",
       "        4.02267575e-02, 5.29105142e-02, 2.75380518e-02, 2.35433728e-02,\n",
       "        1.10538239e-02, 7.96966441e-03, 6.41238084e-03, 6.01874851e-03,\n",
       "        5.38394600e-03, 5.18816058e-03, 6.05364796e-03, 1.08309919e-02,\n",
       "        1.30734034e-02, 7.78630190e-03, 4.43308847e-03, 3.93999647e-03,\n",
       "        5.11085056e-03, 5.05174790e-03, 4.82036639e-03, 4.23052628e-03,\n",
       "        5.26801962e-03, 7.53262313e-03, 1.10618668e-02, 1.25293853e-02,\n",
       "        1.26818987e-02, 1.04200114e-02, 1.05701191e-02, 1.08256238e-02,\n",
       "        9.38726775e-03, 6.19565044e-03, 3.16603761e-03, 1.60648918e-03,\n",
       "        1.52684376e-03, 2.20229663e-03, 2.57697282e-03, 2.74817832e-03,\n",
       "        1.47100503e-03, 5.87979739e-04, 3.29406292e-04, 9.15494631e-04,\n",
       "        1.18480285e-03, 4.43651021e-04, 7.34826463e-05, 2.60393663e-05,\n",
       "        2.30896403e-05, 6.85654913e-06, 7.92519415e-07, 4.92760144e-08,\n",
       "        1.78126247e-09, 1.18057716e-10, 1.01116414e-10, 5.19583508e-11,\n",
       "        3.70050240e-11, 5.91622237e-11, 1.09689688e-10, 2.59872707e-10,\n",
       "        1.19395396e-10, 2.85806878e-10, 2.78577938e-10, 6.96864302e-11],\n",
       "       dtype=float32),\n",
       " array([21.90080592, 14.47813799, 19.16125999, 16.18321595, 17.31833812,\n",
       "        18.8469823 , 44.66474967]),\n",
       " array([-0.02151507, -0.02576342, -0.08391564,  0.00900448,  0.01394758,\n",
       "         0.00646398]),\n",
       " 460)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# The next code loads the saved numpy array of our extracted features\n",
    "# The first 5 components are features, and the last one is the label.\n",
    "features_label = np.load(Path('Data/features_label.npy'), allow_pickle=True)\n",
    "features_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our numpy arrays\n",
    "features = []\n",
    "for i in range(0, len(features_label)):\n",
    "    features.append(np.concatenate((features_label[i][0], features_label[i][1], \n",
    "                features_label[i][2], features_label[i][3],\n",
    "                features_label[i][4]), axis=0))\n",
    "labels = []\n",
    "for i in range(0, len(features_label)):\n",
    "    labels.append(np.array(features_label[i][5]))\n",
    "                \n",
    "X = np.array(features)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = []\n",
    "for i in labels:\n",
    "    store.append(i.tolist())\n",
    "s = set(store)\n",
    "n_unique_labels = len(s)"
   ]
  },
  {
   "source": [
    "##  Preparing data: Hot Enconding and Pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "460\n8\n"
     ]
    }
   ],
   "source": [
    "print(y[0])\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting between validation and training and testing\n",
    "train_prop = int(0.7*len(X))\n",
    "val_prop = int(0.15*(len(X)))\n",
    "\n",
    "\n",
    "X_train = X[:train_prop]\n",
    "Y_train = y[:train_prop]\n",
    "\n",
    "X_validation = X[train_prop:(train_prop + val_prop)]\n",
    "Y_validation = y[train_prop:(train_prop + val_prop)]\n",
    "\n",
    "X_test = X[(train_prop + val_prop):]\n",
    "Y_test = y[(train_prop + val_prop):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train = torch.FloatTensor(ss.fit_transform(X_train))\n",
    "Y_train = torch.LongTensor(Y_train)\n",
    "\n",
    "X_test = torch.FloatTensor(ss.fit_transform(X_test))\n",
    "Y_test = torch.LongTensor(Y_test)\n",
    "\n",
    "X_validation = torch.FloatTensor(ss.fit_transform(X_validation))\n",
    "Y_validation = torch.LongTensor(Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "289\n45\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=193, out_features=289, bias=True)\n",
       "  (fc2): Linear(in_features=289, out_features=45, bias=True)\n",
       "  (fc3): Linear(in_features=45, out_features=30, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_feat, output_feat):\n",
    "        super().__init__()\n",
    "        a = int((input_feat + input_feat/2))\n",
    "        b = int((output_feat + output_feat/2))\n",
    "\n",
    "        self.fc1 = nn.Linear(input_feat, a)\n",
    "        self.fc2 = nn.Linear(a, b)\n",
    "        self.fc3 = nn.Linear(b, output_feat)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "\n",
    "        x = F.log_softmax(self.fc3(x), dim=0)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Classifier(input_feat=X_train.size()[1], output_feat=n_unique_labels)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Classifier(input_feat=X_train.size()[1], output_feat=n_unique_labels)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to +infinity\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(epoch)\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    lower_bound_index = 0\n",
    "    for upper_bound_index in range(1,11):\n",
    "    \n",
    "        index_range = range(lower_bound_index,\n",
    "                            (upper_bound_index*(len(X_train)//10)))\n",
    "\n",
    "        lower_bound_index = upper_bound_index\n",
    "\n",
    "        x = X_train[index_range]\n",
    "        y = Y_train[index_range]\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(x) # log_ps\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*X_train.size(0)\n",
    "\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # prep model for evaluation\n",
    "    lower_bound_index = 0\n",
    "    for upper_bound_index in range(1,11):\n",
    "    \n",
    "        index_range = range(lower_bound_index,\n",
    "                            (upper_bound_index*(len(X_validation)//10)))\n",
    "\n",
    "        lower_bound_index = upper_bound_index\n",
    "\n",
    "        x = X_validation[index_range]\n",
    "        y = Y_validation[index_range]\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(x) # log_ps\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y) \n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*X_validation.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(X_train)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_loss = valid_loss/len(X_validation)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), Path('Data/model.pt'))\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(X_train.size()[1], n_unique_labels)\n",
    "model.load_state_dict(torch.load(Path('Data/model.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "test_losses = []\n",
    "\n",
    "model.eval() # prepare model for evaluation\n",
    "# To speed up calculations, forget the gradients, etc.\n",
    "with torch.no_grad():\n",
    "    lower_bound_index = 0\n",
    "    for upper_bound_index in range(1,11):\n",
    "    \n",
    "        index_range = range(lower_bound_index,\n",
    "                            (upper_bound_index*(len(X_validation)//10)))\n",
    "\n",
    "        lower_bound_index = upper_bound_index\n",
    "\n",
    "        x = X_test[index_range]\n",
    "        y = Y_test[index_range]\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(x) # log_ps\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*x.size(0)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        ps = torch.exp(output) # cuz our model outputs log-probability\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        \n",
    "        equals = (top_class == y.view(*top_class.shape))\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))/(len(range(1,11)))\n",
    "\n",
    "        print(\"Test Loss: {:.3f}.. \".format(test_loss/len(X_test)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  }
 ]
}